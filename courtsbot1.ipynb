{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMPNLcpyR7YqMYDi7hUSCwz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dongjaeseo/AI_Maths/blob/main/courtsbot1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "id": "jvSCTdF2PF57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertModel, BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "CTYscQ3_OGZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels, max_length=32):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.max_length = max_length\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        # Tokenize the text\n",
        "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Your dataset\n",
        "texts = ['i am happy', 'i am sad', 'movie is good', 'hes a bad guy', 'what a good day', 'gloomy day', 'I hate this movie', 'i just love this coffee', 'i dont want to go to class today', 'creepy idea', 'lovely cat', 'great idea']\n",
        "labels = [1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1]\n",
        "\n",
        "# Create an instance of your CustomDataset\n",
        "custom_dataset = CustomDataset(texts, labels)\n",
        "\n",
        "# Create a DataLoader\n",
        "batch_size = 2  # You can adjust this based on your needs\n",
        "custom_dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Example usage\n",
        "for batch in custom_dataloader:\n",
        "    print(batch)"
      ],
      "metadata": {
        "id": "cLcuBQdubj06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load Pre-trained Transformer Model\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "transformer_model = BertForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Step 2: Combine Feature Extraction and Text Classification Model\n",
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, transformer_model, num_classes):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.transformer_model = transformer_model\n",
        "        self.text_classification_head = nn.Linear(transformer_model.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.transformer_model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # For BERT models, the output 'last_hidden_state' is now 'logits'\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Perform text classification using the [CLS] token representation\n",
        "        return logits\n",
        "\n",
        "# Step 3: Initialize and Combine the Models\n",
        "num_classes = 2  # Replace with the number of classes in your text classification task\n",
        "combined_model = CombinedModel(transformer_model, num_classes)\n",
        "\n",
        "# Step 4: Training\n",
        "# Set up your optimizer and loss function\n",
        "optimizer = AdamW(combined_model.parameters(), lr=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Set the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "combined_model.to(device)\n",
        "\n",
        "# Set up your DataLoader and training loop\n",
        "# Replace this with your actual DataLoader and training loop\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "train_dataloader = custom_dataloader\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    combined_model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = combined_model(input_ids, attention_mask)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss:.4f}\")\n",
        "\n",
        "# After training, you can save the model if needed\n",
        "torch.save(combined_model.state_dict(), 'combined_model.pth')"
      ],
      "metadata": {
        "id": "H0yYyof5N6qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from transformers import BertTokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Assuming you have a test dataset (test_dataset) and DataLoader\n",
        "# Replace this with your actual test dataset loading code\n",
        "\n",
        "# Your dataset\n",
        "texts = ['I love this movie', 'i just dont like this coffee', 'i cant wait to go to class today', 'best idea', 'ugly dog', 'not bad idea']\n",
        "# Corrected labels: 0 for negative, 1 for positive\n",
        "labels = [1, 0, 1, 1, 0, 1]\n",
        "\n",
        "# Create an instance of your CustomDataset\n",
        "test_dataset = CustomDataset(texts, labels)\n",
        "\n",
        "# Create a DataLoader\n",
        "batch_size = 2\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "combined_model.eval()\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = combined_model(input_ids, attention_mask)\n",
        "\n",
        "        # Predictions and probabilities\n",
        "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        preds = torch.argmax(probs, dim=1).cpu().numpy()\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "        # Collect predictions, labels, and probabilities\n",
        "        all_labels.extend(labels)\n",
        "        all_preds.extend(preds)\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "# Calculate and print evaluation metrics\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "classification_rep = classification_report(all_labels, all_preds)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n",
        "\n",
        "# Print input texts, true labels, predicted labels, and probabilities\n",
        "for i in range(len(texts)):\n",
        "    print(f\"Text: {texts[i]}, True Label: {labels[i]}, Predicted Label: {all_preds[i]}, Probabilities: {all_probs[i]}\")\n"
      ],
      "metadata": {
        "id": "mJrsaxLyceck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rf2M0R-0Zebv"
      }
    }
  ]
}